# -*- coding: utf-8 -*-
"""SoC_Final_Project_Submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lBNHQW0fZyYEw8rUi-C9a073LWBU0tPm
"""

from google.colab import drive
drive.mount('/content/drive')

!pwd

import os
import cv2
from google.colab.patches import cv2_imshow

path = []
path.append('/content/drive/MyDrive/Colab_Notebooks/SOC_Final_Project/Data/')
path.append('/content/drive/MyDrive/Colab_Notebooks/SOC_Final_Project/Data/tom_cruise_dataset/')  # Images in this folder are named 1_(.)
path.append('/content/drive/MyDrive/Colab_Notebooks/SOC_Final_Project/Data/katrina_kaif_dataset/')  # Images in this folder are named 2_(.)
path.append('/content/drive/MyDrive/Colab_Notebooks/SOC_Final_Project/Data/Elizabeth_Olsen/')  # Images in this folder are named 3_(.)
path.append('/content/drive/MyDrive/Colab_Notebooks/SOC_Final_Project/Data/Scarlett_Johansson/')  # Images in this folder are named 4_(.)

# Defining a special function to resize images, capable of handling corner cases

def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):
    # initialize the dimensions of the image to be resized and
    # grab the image size
    dim = None
    (h, w) = image.shape[:2]

    # if both the width and height are None, then return the
    # original image
    if width is None and height is None:
        return image

    # check to see if the width is None
    if width is None:
        # calculate the ratio of the height and construct the
        # dimensions
        r = height / float(h)
        dim = (int(w * r), height)

    # otherwise, the height is None
    else:
        # calculate the ratio of the width and construct the
        # dimensions
        r = width / float(w)
        dim = (width, int(h * r))

    # resize the image
    resized = cv2.resize(image, dim, interpolation = inter)

    # return the resized image
    return resized

import matplotlib.pyplot as plt
import shutil

from PIL import Image
import os, sys

path = '/content/drive/MyDrive/Colab_Notebooks/SOC_Final_Project/Data'
dirs = os.listdir( path )

def resize():
    for item in dirs:
        if os.path.isfile(path+item):
            im = Image.open(path+item)
            f, e = os.path.splitext(path+item)
            imResize = im.resize((224,224), Image.ANTIALIAS)
            imResize.save(f + ' resized.jpg', 'JPEG', quality=90)

resize()

!pip install git+https://github.com/rcmalli/keras-vggface

!pip install keras_applications

!pip install mtcnn

import tensorflow as tf
import keras
import keras_vggface
from keras_vggface.vggface import VGGFace
import mtcnn
import numpy as np
import matplotlib as mpl
from keras.utils.data_utils import get_file
import keras_vggface.utils
import PIL
import os
import os.path

vggface = VGGFace(model = 'vgg16')
vggface_resnet = VGGFace(model = 'resnet50')
vggface_senet = VGGFace(model = 'senet50')

print(vggface.summary())
print("Inputs: ", vggface.inputs)
print("Outputs: ", vggface.outputs)

train_dataset = keras.utils.image_dataset_from_directory('/content/drive/MyDrive/Colab_Notebooks/SOC_Final_Project/Data', shuffle = True, batch_size = 8, image_size = (224, 224))

os.listdir('/content/drive/MyDrive/Colab_Notebooks/SOC_Final_Project/Data')

data_augmentation = keras.Sequential([keras.layers.RandomFlip("horizontal"),
                                      keras.layers.RandomRotation(0.2),])

vggface_resnet_base = VGGFace(model = 'resnet50', include_top = False, input_shape = (224, 224, 3))

from keras.layers import Flatten, Dense, Input
from keras_vggface.vggface import VGGFace

nb_class = 4

# Freezing the base model
vggface_resnet_base.trainable = False
last_layer = vggface_resnet_base.get_layer("avg_pool").output

# Building up the new model
inputs = tf.keras.Input(shape=(224, 224, 3))

x = data_augmentation(inputs)

x = vggface_resnet_base(x)

x = Flatten(name = 'flatten')(x)

out = Dense(nb_class, name = 'classifier')(x)

custom_vgg_model = keras.Model(inputs, out)

base_learning_rate = 0.0001

custom_vgg_model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = base_learning_rate),
                         loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),
                         metrics = ['accuracy'])

history = custom_vgg_model.fit(train_dataset, epochs = 20)

!pip list

x_test = []

# DO NOT RUN THIS CELL.

from PIL import Image
import os, sys

path = '/content/drive/MyDrive/Colab_Notebooks/SOC_Final_Project/Samples/samples/'
dirs = os.listdir(path)

def resize():
    for item in dirs:
        if os.path.isfile(path+item):
            im = Image.open(path+item)
            f, e = os.path.splitext(path+item)
            imResize = im.resize((224,224), Image.ANTIALIAS)
            imResize.save(f + ' resized.jpg', 'JPEG', quality=90)

resize()

dir_list = os.listdir('/content/drive/MyDrive/Colab_Notebooks/SOC_Final_Project/Samples/samples/')
print(dir_list)

for i in dir_list:
    image = cv2.imread('/content/drive/MyDrive/Colab_Notebooks/SOC_Final_Project/Samples/samples/' + i)
    # image = image_resize(image, 224, 224)
    # image_data = tf.image.encode_jpeg(image)
    # fnames = ['{}_({}).jpg'.format(i, k+1) for k in range(80)]
    # if(len(x_test) < 21):
    cv2_imshow(image)
    x_test.append(image)

len(x_test)

x_test = x_test[0:20]  # This will ensure that running the code again and again does not keep appending to the test set.

prob_model = keras.Sequential([custom_vgg_model, tf.keras.layers.Softmax()])

os.getcwd()

x_test

predictions = prob_model.predict(np.array(x_test))
predictions

predictions.shape

from tensorflow.python.ops.gen_math_ops import arg_max
output_labels = []

for i in range(predictions.shape[0]):
    output_labels.append(predictions[i].argmax())

output_labels

