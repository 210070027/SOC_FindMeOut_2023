# -*- coding: utf-8 -*-
"""SoC_Week2_Assg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FCxF8ZvRrsCXbfs51rBbRvhs6bOZFKQt
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# %matplotlib inline

from google.colab import files # Colab-specific library to load files
uploaded = files.upload() # Upload file; here we will upload the Iris dataset (csv file)

# Confirm upload
for fn in uploaded.keys(): 
  print('You uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

"""1. Reading the data from the CSV file into a pandas data frame

"""

data=pd.read_csv("Iris.csv")

"""2. Printing the number of columns and rows using functions

"""

print("Number of Rows: " + str(len(data.axes[0])))
print("Number of Columns: " + str(len(data.axes[1])))

"""3. Printing the name of each column


"""

for col in data.columns:
    print(col)

"""4. Printing the data type of each column"""

datatypes = data.dtypes
datatypes

"""5. Finding the mean and variance of each column"""

data1 = data.drop("Species", axis=1) # Dropping the last column as it is of type object

for col in data1.columns:
    print("Column mean for " + col + " is " + str(data1[col].mean(axis=0))) 
    print("Column variance for " + col + " is " + str(data1[col].var(axis=0)))

"""6. Plotting histograms for each column"""

# First, we plot the histograms, fixing number of bins manually (checking which value is better by looking at the graphs).
# Later, I have used another method too.

hist = data['SepalLengthCm'].hist(bins=10)

hist = data['SepalWidthCm'].hist(bins=10)

hist = data['PetalLengthCm'].hist(bins=8)

hist = data['PetalWidthCm'].hist(bins=8)

# Given below are the histograms for all columns plotted together. To ensure just the right size of bins, I have used The Freedman-Diaconis rule.
# It is very robust and works well in practice. The bin-width is set to h=2×IQR×n^(−1/3). So the number of bins is (max−min)/h, where n is the 
# number of observations, max is the maximum value and min is the minimum value in that column.

data3 = data1.drop("Id", axis=1) # Dropping columns 'Id' and 'Species' 

for col in data3.columns:
    q1_x = np.percentile(data3[col], 25, interpolation='midpoint')
    q3_x = np.percentile(data3[col], 75, interpolation='midpoint') 
    iqr = q3_x - q1_x
    h=2*iqr*pow(len(data3[col].axes[0]), -1/3)
    number = (data3.max(axis=0)[col] - data3.min(axis=0)[col])
    number = number/h
    hist = data3[col].hist(bins = int(number))

data["Species"].unique()

"""7. Printing the correlation  matrix and heat map for the data frame"""

matrix = data3.corr() # By default, the corr method uses the Pearson coefficient of correlation
print(matrix)

sns.heatmap(data3, annot=True)

"""8. Plotting scatter plot between each pair of columns"""

array = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']

for i in range(len(array)):
    for j in range(i+1, len(array)):
        plt.scatter(data1[array[i]], data1[array[j]])
        plt.ylabel(array[i])
        plt.xlabel(array[j])
        plt.grid()
        plt.show()

"""9. Plotting QQ-Plots for each column"""

import statsmodels.api as sm

for col1 in data3:
    fig = sm.qqplot(data3[col1], line='45')
    plt.ylabel(col1)
    plt.xlabel("Theoretical quantiles")
    plt.show()

# CONCLUSIONS FROM QQ PLOT:
# 1. For SepalLengthCm, the distribution is left-skewed wrt to the theoretical distribution (i.e., a Gaussian).
# 2. For SepalWidthCm, the distribution is left-skewed wrt to the theoretical distribution.
# 3. For PetalLengthCm, the distribution is left-skewed, and there are also gaps in the values. 
# 4. For PetalWidthCm, the distribution is left-skewed, and there is a small gap in values.

"""10. Plotting the Box and Whiskers plot for each column"""

data2 = data.drop("Id", axis=1) # Dropping the first column as it does not contain any information
boxplot = data2.boxplot(column=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'])

# The above box and whiskers plots tell us that values of SepalWidthCm have very little range, that is the values are closely huddled together.
# Also, around 4 values are outliers. An outlier is an observation that is numerically distant from the rest of the data.
# For example, outside 1.5 times the interquartile range above the upper quartile and below the lower quartile ( Q3 + 1.5 * IQR or Q1 – 1.5 * IQR).

# Whereas, the values of PetalLengthCm have a larger interquantile range, as indicated by the "longer" box.
# Also, the presence of the median line closer to the third quantile indicates that the distribution is negatively skewed. 

# SepalLengthCm and PetalWidthCm have moderate ranges. 
# Also, for PetalWidthCm, the presence of the median line closer to the third quantile indicates that the distribution is negatively skewed.
# Whereas, for SepalLengthCm, the distribution is very close to a normal distribution.

"""11. Strategies to handle unknown data"""

# In order to preprocess the data, that is, make it ready for further analysis, we need to clean the data.
# Data cleaning includes removing rows with NaN values or too much missing data, replacing some missing values with either 0 
# or the mean of that column, removing punctuations/emoticons and converting to lowercase for text data for eg, in some cases,
# removing extreme values as they may affect the results etc. 

# After the raw data has been converted to clean data, it is ready to be worked upon!
# In order to know our data better, we can start by printing the first few rows of our clean data set, followed by printing the size
# of the data set (number of rows and columns), data type of each column, as well as some statistical measures such as the mean and
# variance of each column. This can be followed by some basic Exploratory Data Analysis (EDA), an approach of analyzing data sets to
# summarize their main characteristics, often using statistical graphics and other data visualization methods. We can plot bar charts,
# histograms, qq plots, correlation matrices, heaat maps, scatter plots, pie carts, line graphs, violin graphs etc. depending on the
# data type and application involved.

# In cases where our strategy does not work, we must try and see what is causing a problem. Is it the data that's corrupted or 
# non-representative (is systematically different from the true distribution)? Or is it inadequate? Such problems are commonly faced 
# in data analysis and can be solved by collecting more data. We may also be getting dissatisfactory results if we're not plotting the 
# correct graph for the given type of data.

"""12. Splitting the dataset based on 'Species'"""

grouped = data.groupby(data['Species'])
Species1 = grouped.get_group('Iris-setosa')
Species2 = grouped.get_group('Iris-versicolor')
Species3 = grouped.get_group('Iris-virginica')

Species1.head()

Species2.head()

Species3.head()

print("Species1 has " + str(len(Species1.axes[0])) + " samples.")
print("Species2 has " + str(len(Species2.axes[0])) + " samples.")
print("Species3 has " + str(len(Species3.axes[0])) + " samples.")

boxplot = Species1.boxplot(column=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'])  # Iris-setosa

# Observation: Petal width is almost the same for all samples, i.e., range is extremely small.  # Iris-versicolor

boxplot = Species2.boxplot(column=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'])

boxplot = Species3.boxplot(column=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'])  # Iris-virginica

# As can be clearly observed from the above plots, each species of flowers has a particular range of values for sepal length and width,
# and petal length and width. And these ranges are substantially smaller than the ranges we observed earlier when we plotted box and 
# whiskers plots for all three species combined.

S1 = Species1.drop("Species", axis=1)
S1 = S1.drop("Id", axis=1)

matrix = S1.corr() # By default, the corr method uses the Pearson coefficient of correlation
print(matrix)

sns.heatmap(S1, annot=True)

S2 = Species2.drop("Species", axis=1)
S2 = S2.drop("Id", axis=1)

matrix = S2.corr() # By default, the corr method uses the Pearson coefficient of correlation
print(matrix)

sns.heatmap(S2, annot=True)

S3 = Species3.drop("Species", axis=1)
S3 = S3.drop("Id", axis=1)

matrix = S3.corr() # By default, the corr method uses the Pearson coefficient of correlation
print(matrix)

sns.heatmap(S3, annot=True)

# We can conclude that the heat maps for all species are roughly the same, indicating that the relation between different parameters is similar 
# for all species.